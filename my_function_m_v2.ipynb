{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "# from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "# import multiprocessing as mp\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import Dropout\n",
    "# from keras import optimizers\n",
    "# from keras.constraints import maxnorm\n",
    "from numpy.random import seed\n",
    "#from tensorflow import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(y, y_pred, y_train=None):\n",
    "    sse = 0; sst = 0\n",
    "    if y_train is None:        \n",
    "        y_mean = np.mean(y)\n",
    "    else:\n",
    "        y_mean = np.mean(y_train)\n",
    "    for i in range(len(y)):\n",
    "        sse += (y[i] - y_pred[i]) ** 2\n",
    "        sst += (y[i] - y_mean) ** 2\n",
    "    r2_score = 1 - (sse / sst)\n",
    "    return r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_loo(model, X, y):\n",
    "    loo = LeaveOneOut()\n",
    "    y_pred = []\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        tmp = model.predict(X_test)\n",
    "        #tmp = scaler_y.inverse_transform(tmp)\n",
    "        y_pred.append(list(tmp)[0])\n",
    "    r2 = r2_score(y_train, y_pred)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out(estimator, X, y, fit_time=False):\n",
    "    n_data = X.shape[0]\n",
    "    times = []; y_preds = []\n",
    "    range_ = list(range(n_data))\n",
    "    for i in range(n_data):\n",
    "        train = np.setdiff1d(range_, i)\n",
    "        X_tmp = X[train, :]\n",
    "        y_tmp = y[train]\n",
    "        mdl = estimator\n",
    "        t0 = time.time()\n",
    "        mdl.fit(X_tmp, y_tmp)\n",
    "        time_ = time.time() - t0\n",
    "        times.append(time_)\n",
    "        y_pred = mdl.predict(X[i, :][np.newaxis, :])\n",
    "        y_preds.append(np.asscalar(y_pred))\n",
    "    fit_time = np.mean(times)\n",
    "    if fit_time == True:\n",
    "        return fit_time, y_preds\n",
    "    else:\n",
    "        return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_score(y, y_pred):\n",
    "    if isinstance(y, np.ndarray) or isinstance(y, list):\n",
    "        n_data = len(y)\n",
    "        sum_err = 0\n",
    "        for i in range(n_data):\n",
    "            err = y[i] - y_pred[i]\n",
    "            sum_err += (err ** 2)\n",
    "        return sum_err / n_data\n",
    "    else:        \n",
    "        return (y - y_pred) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(estimator, X, y, n=5):\n",
    "    kf = KFold(n_splits=n, random_state=42, shuffle=False)\n",
    "    tmp_mse = []; tmp_r2 = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_, X_test = X[train_index], X[test_index]\n",
    "        y_train_, y_test = y[train_index], y[test_index]\n",
    "        estimator.fit(X_train_, y_train_)\n",
    "        y_pred = estimator.predict(X_test)\n",
    "        r2_ = r2_score(y_test, y_pred)\n",
    "        mse_ = mse_score(y_test, y_pred)\n",
    "        if (np.isnan(mse_) or np.isinf(mse_)):\n",
    "            tmp_mse.append(100)\n",
    "        else:\n",
    "            tmp_mse.append(mse_)\n",
    "        if (np.isnan(r2_) or np.isinf(r2_)):\n",
    "            tmp_r2.append(0)\n",
    "        else:\n",
    "            tmp_r2.append(r2_)\n",
    "    sum_mse = np.average(tmp_mse)\n",
    "    sum_r2 = np.average(tmp_r2)\n",
    "    return sum_mse, sum_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loo_fit_predict(estimator, X_train, y_train, X_test, y_test, test_index):\n",
    "    # standardize\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    print(test_index)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loo_cv_parallel(estimator, X, y):\n",
    "    print(\"start\")\n",
    "    loo = LeaveOneOut()\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    y_pred = [pool.apply(loo_fit_predict, args=(estimator,X[train_index],y[train_index],X[test_index], \n",
    "                                                y[test_index], test_index)) for train_index, test_index in loo.split(X)]\n",
    "    pool.close() \n",
    "    r2 = r2_score(y, y_pred)\n",
    "    print(r2)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_fit_predict(estimator, X_train, y_train, X_test, y_test):\n",
    "    # standardize\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred, y_train)\n",
    "    mse = mse_score(y_test, y_pred)\n",
    "#    for i in range(len(y_pred)):\n",
    "#        print(y_test[i], y_pred[i])\n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv_parallel(estimator, X, y, n=5):\n",
    "    kf = KFold(n_splits=n, random_state=42, shuffle=False)\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    tmp = [pool.apply(k_fold_fit_predict, args=(estimator,X[train_index],y[train_index],X[test_index], \n",
    "                                                y[test_index])) for train_index, test_index in kf.split(X)]\n",
    "    pool.close() \n",
    "    tmp = [y for x in tmp for y in x]\n",
    "    tmp_mse = []; tmp_r2 = []\n",
    "    for i in range(len(tmp)):\n",
    "        if i%2 == 0:\n",
    "            tmp_mse.append(tmp[i])\n",
    "        else:\n",
    "            tmp_r2.append(tmp[i])\n",
    "    sum_mse = np.average(tmp_mse)\n",
    "    sum_r2 = np.average(tmp_r2)\n",
    "    if (np.isnan(sum_mse) or np.isinf(sum_mse)):\n",
    "        sum_mse = 100\n",
    "    if (np.isnan(sum_r2) or np.isinf(sum_r2)):\n",
    "        sum_r2 = 0\n",
    "    return sum_mse, sum_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    max_ = np.max(X, axis=0)\n",
    "    min_ = np.min(X, axis=0)\n",
    "    X_norm = (X - min_) / (max_ - min_)\n",
    "    return max_, min_, X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X):\n",
    "    mean_ = np.mean(X, axis=0)\n",
    "    std_ = np.std(X, axis=0)\n",
    "    X_norm = (X - mean_) / std_\n",
    "    return X_norm, mean_, std_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qsar_param(y, y_pred, d_r2m=True):\n",
    "    results = []\n",
    "    _, _, y = normalize(y)\n",
    "    _, _, y_pred = normalize(y_pred)\n",
    "    y_mean = np.mean(y); y_pred_mean = np.mean(y_pred)\n",
    "    # calculate r2\n",
    "    num = 0; den_1 = 0; den_2 = 0\n",
    "    for i in range(len(y)):\n",
    "        num += (y[i] - y_mean) * (y_pred[i] - y_pred_mean)\n",
    "        den_1 += (y_pred[i] - y_pred_mean) ** 2\n",
    "        den_2 += (y[i] - y_mean) ** 2\n",
    "    r2 = num ** 2 / (den_1 * den_2)\n",
    "    results = {\"r2\": r2}\n",
    "    # calculate k and k_dash\n",
    "    n_data = len(y)\n",
    "    dot_ = 0; y_pred2 = 0; y2 = 0\n",
    "    for i in range(n_data):\n",
    "        dot_ += (y[i] * y_pred[i])\n",
    "        y_pred2 += y_pred[i] ** 2\n",
    "        y2 += y[i] ** 2\n",
    "    k = np.sum(dot_) / np.sum(y_pred2)\n",
    "    k_dash = np.sum(dot_) / np.sum(y2)\n",
    "    results[\"k\"] = k\n",
    "    results[\"k_dash\"] = k_dash\n",
    "    # calculate r2_0 and r2_0_dash\n",
    "    num = 0; num_dash = 0; den = 0; den_dash = 0\n",
    "    for i in range(n_data):\n",
    "        num += (y[i] - (k * y_pred[i])) ** 2\n",
    "        num_dash += (y_pred[i] - (k_dash * y[i])) ** 2\n",
    "        den += (y[i] - y_mean) ** 2\n",
    "        den_dash += (y_pred[i] - y_pred_mean) ** 2\n",
    "    r2_0 = 1 - (num / den)\n",
    "    r2_0_dash = 1 - (num_dash / den_dash)\n",
    "    #results.append(r2_0)\n",
    "    #results.append(r2_0_dash)\n",
    "    r2r0 = (r2 - r2_0)/r2\n",
    "    r2r0_dash = (r2 - r2_0_dash)/r2\n",
    "    results[\"r2r0\"] = r2r0\n",
    "    results[\"r2r0_dash\"] = r2r0_dash\n",
    "    r0r0_dash = np.abs(r2_0 - r2_0_dash)\n",
    "    results[\"r0r0_dash\"] = r0r0_dash\n",
    "    # calculate rm2 and rm2_dash\n",
    "    rm2 = r2 * (1 - np.sqrt(r2 - r2_0))\n",
    "    rm2_dash = r2 * (1 - np.sqrt(r2 - r2_0_dash))\n",
    "    results[\"rm2\"] = rm2\n",
    "    results[\"rm2_dash\"] = rm2_dash\n",
    "    #results.append(rm2)\n",
    "    #results.append(rm2_dash)\n",
    "    # calculate rm2_bar and d_rm2\n",
    "    rm2_bar = (rm2 + rm2_dash) / 2\n",
    "    d_rm2 = np.abs(rm2 - rm2_dash)\n",
    "    results[\"rm2_bar\"] = rm2_bar\n",
    "    results[\"d_rm2\"] = d_rm2\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_random(estimator, X, y, n=10):\n",
    "    # non-random\n",
    "    estimator.fit(X, y)\n",
    "    y_pred = estimator.predict(X)    \n",
    "    r2_nr = r2_score(y, y_pred)\n",
    "    r_nr = np.sqrt(r2_nr)\n",
    "    n_data = X.shape[0]\n",
    "    # random\n",
    "    r2_rand = []\n",
    "    range_ = list(range(n_data))\n",
    "    for i in range(n):\n",
    "        new_range_ = copy.deepcopy(range_)\n",
    "        np.random.shuffle(new_range_)\n",
    "        y_new = []\n",
    "        for i in new_range_:\n",
    "            y_new.append(y[i])\n",
    "        y_new = np.array(y_new)\n",
    "        estimator.fit(X, y_new)\n",
    "        y_pred = estimator.predict(X)\n",
    "        r2_rand.append(r2_score(y_new, y_pred))\n",
    "    r2_rand_avg = np.average(r2_rand)\n",
    "    rp = r_nr * np.sqrt(r2_nr - r2_rand_avg)\n",
    "    return rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leverage(XtX, X):\n",
    "    levs = []\n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i,:]\n",
    "        lev = x.dot(XtX).dot(x.T)\n",
    "        levs.append(lev)\n",
    "    return levs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applicability_domain(X_train, X_test, y_train_act, \n",
    "                         y_train_pred, y_test_act, y_test_pred,fig_idx=0):\n",
    "    # using wilson map\n",
    "    X_train, _, _ = standardize(X_train)\n",
    "    X_test, _, _ = standardize(X_test)\n",
    "    n, p = X_train.shape\n",
    "    # calculate standardized residuals\n",
    "    err_train = []; res_train = []\n",
    "    for i in range(len(y_train_pred)):\n",
    "        err_train.append(y_train_act[i] - y_train_pred[i])\n",
    "    rmse_train = np.sqrt(mse_score(y_train_act, y_train_pred))\n",
    "    for i in range(len(y_train_pred)):\n",
    "        tmp = err_train[i]/rmse_train\n",
    "        res_train.append(tmp)\n",
    "    err_test = []; res_test = []\n",
    "    for i in range(len(y_test_pred)):\n",
    "        err_test.append(y_test_act[i] - y_test_pred[i])\n",
    "    rmse_test = np.sqrt(mse_score(y_test_act, y_test_pred))\n",
    "    for i in range(len(y_test_pred)):\n",
    "        tmp = err_test[i]/rmse_test\n",
    "        res_test.append(tmp)    \n",
    "    #res_test = [a/rmse_test for a in err_test]\n",
    "    # calculate leverage\n",
    "    XtX = X_train.T.dot(X_train)\n",
    "    XtX = np.linalg.pinv(XtX)\n",
    "    lev_train = leverage(XtX, X_train)\n",
    "    lev_test = leverage(XtX, X_test)\n",
    "    h_star = (3 * (p + 1)) / n\n",
    "    print(h_star)\n",
    "    #return (lev_train, res_train, lev_test, res_test, h_star)\n",
    "#     print(lev_train)\n",
    "#     print(res_train)\n",
    "    #plotting\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.scatter(lev_train, res_train,marker='o', c='b', label='Train')\n",
    "    plt.scatter(lev_test, res_test, marker='^', c='r', label='Test')\n",
    "    plt.axhline(y=3, c='k', linewidth=0.8)\n",
    "    plt.axhline(y=-3, c='k', linewidth=0.8)\n",
    "    plt.axvline(x=h_star, c='k', linewidth=0.8, linestyle='dashed')\n",
    "    #plt.xticks([0,0.1,0.2,0.3,0.4,0.5,h_star,0.6],[0,0.1,0.2,0.3,0.4,0.5,\"h$^*$\",0.6])\n",
    "    plt.text(h_star+0.001, 0, \"h$^*$\")\n",
    "    plt.xlim(0, h_star + 0.1)\n",
    "    plt.ylim(-4, 4)\n",
    "    plt.xlabel('leverage', fontname=\"Arial\", fontsize=12)\n",
    "    plt.ylabel('standardized residual', fontname=\"Arial\", fontsize=12)\n",
    "    plt.legend(prop={'family':\"Arial\", 'size':12}, loc='upper right')\n",
    "    plt.savefig('./app_domain_{}.jpg'.format(fig_idx), format='jpg', dpi=1000, bbox_inches=\"tight\")    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasRegressor\n",
    "def create_model_sa(input_dim=5):\n",
    "    # create model\n",
    "    seed(1)\n",
    "    set_random_seed(2)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='SGD')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimulatedAnnealing():\n",
    "#     def __init__(self, t_init=100, t_fin=25, alpha=5, n_iter=100,\n",
    "#                  rate=0.9, max_feat=1, seed=42):\n",
    "#         self.t_init = t_init\n",
    "#         self.t_fin = t_fin\n",
    "#         self.alpha = alpha\n",
    "#         self.n_iter = n_iter\n",
    "#         self.seed = seed\n",
    "#         self.rng = np.random.RandomState(seed)\n",
    "#         self.max_feat = max_feat\n",
    "#         self.rate = rate\n",
    "#         self.idx = []\n",
    "    \n",
    "#     def stack_data(self, X, idx):\n",
    "#         for i in range(len(idx)):\n",
    "#             if i == 0:\n",
    "#                 X_res = X[:, idx[i]][:, np.newaxis]\n",
    "#             else:\n",
    "#                 X_res = np.hstack((X_res, X[:, idx[i]][:, np.newaxis]))\n",
    "#         return X_res\n",
    "    \n",
    "#     def check(self, idx, list_idx):\n",
    "#         exist = False\n",
    "#         for i in range(len(list_idx)):\n",
    "#             tmp = list_idx[i]\n",
    "#             check = all(elem in idx  for elem in tmp)\n",
    "#             if check:\n",
    "#                 exist = True\n",
    "#         return exist\n",
    "    \n",
    "#     def compute_mse_r2(self, X, y):\n",
    "#         \"\"\"\n",
    "#         if not self.idx: \n",
    "#             idx_ = self.rng.choice(np.arange(self.n_feat), self.max_feat,replace=False)\n",
    "#             idx_ = np.sort(idx_).tolist()\n",
    "#             self.idx.append(idx_)\n",
    "#         else:\n",
    "#             idx_ = self.rng.choice(np.arange(self.n_feat), self.max_feat,replace=False)\n",
    "#             idx_ = np.sort(idx_).tolist()\n",
    "#             flag = self.check(idx_, self.idx)\n",
    "#             while flag:\n",
    "#                 idx_ = self.rng.choice(np.arange(self.n_feat), self.max_feat,replace=False)\n",
    "#                 idx_ = np.sort(idx_)\n",
    "#                 flag = self.check(idx_, self.idx)\n",
    "#             self.idx.append(idx_)\n",
    "#         \"\"\" \n",
    "#         idx_ = self.rng.choice(np.arange(self.n_feat), self.max_feat,replace=False)\n",
    "#         idx_ = np.sort(idx_).tolist()                    \n",
    "#         X_tmp = self.stack_data(X, idx_)\n",
    "#         \"\"\"\n",
    "#         np.random.seed(self.seed)\n",
    "#         # build pipeline\n",
    "#         estimators = []\n",
    "#         estimators.append(('standardize', StandardScaler()))\n",
    "#         estimators.append(('mlp', KerasRegressor(build_fn=create_model_sa, input_dim=self.input_dim, \n",
    "#                                                  epochs=100, batch_size=5, verbose=0)))\n",
    "#         pipeline = Pipeline(estimators)\n",
    "#         # cross validation\n",
    "#         kfold = KFold(n_splits=10, random_state=self.seed)\n",
    "#         cv_results = cross_validate(pipeline, X_tmp, y, cv=kfold, scoring=('r2', 'neg_mean_squared_error'), \n",
    "#                             return_train_score=True, n_jobs=-1)\n",
    "#         mse = -np.mean(cv_results['test_neg_mean_squared_error'])\n",
    "#         r2 = np.mean(cv_results['test_r2'])\n",
    "#         \"\"\"\n",
    "#         estimator = KerasRegressor(build_fn=create_model_sa, input_dim=self.max_feat, epochs=100, batch_size=8, verbose=0)\n",
    "#         mse, r2 = k_fold_cv_parallel(estimator, X_tmp, y, n=5)\n",
    "#         return idx_, mse, r2\n",
    "    \n",
    "#     def select(self, X, y, label):\n",
    "#         self.n_feat = X.shape[1]\n",
    "#         # initialization\n",
    "#         idx, mse, r2 = self.compute_mse_r2(X, y)\n",
    "#         t = self.t_init\n",
    "#         mse_list = [mse]\n",
    "#         r2_list = [r2]\n",
    "#         t_list = [t]\n",
    "#         while t >= self.t_fin:\n",
    "#             print(\"\\n {} - temperature: {}\".format(self.max_feat, t))\n",
    "#             for _ in tqdm(range(self.n_iter)):\n",
    "#                 # new solution\n",
    "#                 idx_new, mse_new, r2_new = self.compute_mse_r2(X, y)\n",
    "#                 if mse_new <= mse:\n",
    "#                     mse = mse_new\n",
    "#                     idx = idx_new\n",
    "#                     r2 = r2_new\n",
    "#                 else:             \n",
    "#                     err_ = mse_new - mse\n",
    "#                     k_ = -(self.t_init * np.log(0.8)) / err_\n",
    "#                     proba = np.exp(-(k_ * err_) / t)\n",
    "#                     rand_ = self.rng.rand()\n",
    "#                     if rand_ < proba:\n",
    "#                         mse = mse_new\n",
    "#                         idx = idx_new\n",
    "#                         r2 = r2_new\n",
    "#             # update t\n",
    "#             t *= self.rate\n",
    "#             t_list.append(t)\n",
    "#             mse_list.append(mse)\n",
    "#             r2_list.append(r2)\n",
    "#             print(\"desc: {}; mse: {}; r2: {}\".format(label[idx], mse, r2))\n",
    "#         return idx, [t_list, mse_list, r2_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasRegressor\n",
    "def create_model(input_dim=5, hidden_layer=1, hidden_node=5, dropout_rate=0, optimizer='SGD', learn_rate=0.01, \n",
    "                 momentum=0.0, activation='relu'):\n",
    "    # create model\n",
    "    seed(1)\n",
    "    set_random_seed(2)\n",
    "    model = Sequential()\n",
    "    for i in range(hidden_layer):\n",
    "        if i == 0:\n",
    "            model.add(Dense(hn, input_dim=input_dim, activation=activation))\n",
    "            if dropout_rate > 0:\n",
    "                model.add(Dropout(dropout_rate, seed=1))\n",
    "        else:\n",
    "            model.add(Dense(hn, activation=activation))\n",
    "            if dropout_rate > 0:\n",
    "                model.add(Dropout(dropout_rate, seed=1))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    # Compile model\n",
    "    if optimizer == 'SGD':\n",
    "        opt = optimizers.SGD(lr=learn_rate, momentum=momentum)\n",
    "    elif optimizer == 'RMSprop':\n",
    "        opt = optimizers.RMSprop(lr=learn_rate)\n",
    "    elif optimizer == 'Adagrad':\n",
    "        opt = optimizers.Adagrad(lr=learn_rate)\n",
    "    elif optimizer == 'Adadelta':\n",
    "        opt = optimizers.Adadelta(lr=learn_rate)        \n",
    "    elif optimizer == 'Adam':\n",
    "        opt = optimizers.Adam(lr=learn_rate)                \n",
    "    elif optimizer == 'Adamax':\n",
    "        opt = optimizers.Adamax(lr=learn_rate)                \n",
    "    else:\n",
    "        opt = optimizers.Nadam(lr=learn_rate)                \n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_list(y):\n",
    "    res = []\n",
    "    for i in range(len(y)):\n",
    "        res.append(y[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
